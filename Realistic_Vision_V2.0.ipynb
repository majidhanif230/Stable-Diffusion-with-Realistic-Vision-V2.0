{"cells":[{"cell_type":"markdown","metadata":{},"source":["# dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T16:01:57.506107Z","iopub.status.busy":"2024-08-19T16:01:57.505390Z","iopub.status.idle":"2024-08-19T16:02:12.703804Z","shell.execute_reply":"2024-08-19T16:02:12.702880Z","shell.execute_reply.started":"2024-08-19T16:01:57.506075Z"},"trusted":true},"outputs":[],"source":["!pip install torch torchvision diffusers accelerate huggingface_hub datasets"]},{"cell_type":"markdown","metadata":{},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import torch\n","from PIL import Image\n","from diffusers import StableDiffusionPipeline\n","from huggingface_hub import login\n","from accelerate import Accelerator\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms"]},{"cell_type":"markdown","metadata":{},"source":["# Login with Hugging-face"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Step 1: Authenticate with Hugging Face\n","login('')  # Replace with your Hugging Face access token"]},{"cell_type":"markdown","metadata":{},"source":["# Set up the environment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Step 2: Set up the environment\n","accelerator = Accelerator()\n","device = accelerator.device  # Automatically uses GPU if available"]},{"cell_type":"markdown","metadata":{},"source":["# Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Step 3: Load the Stable Diffusion model\n","model_id = \"SG161222/Realistic_Vision_V2.0\"  # Use the specified model\n","pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)\n","pipe = pipe.to(device)\n","\n","# Disable the safety checker (optional, use with caution)\n","def dummy_safety_checker(images, **kwargs):\n","    return images, [False] * len(images)\n","pipe.safety_checker = dummy_safety_checker"]},{"cell_type":"markdown","metadata":{},"source":["# Prepare Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T16:28:30.380922Z","iopub.status.busy":"2024-08-19T16:28:30.380539Z","iopub.status.idle":"2024-08-19T16:34:12.973083Z","shell.execute_reply":"2024-08-19T16:34:12.972093Z","shell.execute_reply.started":"2024-08-19T16:28:30.380891Z"},"trusted":true},"outputs":[],"source":["# Step 4: Prepare the dataset\n","image_dir = \"/kaggle/input/private/images\"  # Path to your images\n","prompt_dir = \"/kaggle/input/private/prompts\"  # Path to your prompts\n","\n","# Create a custom dataset class\n","class CustomDataset(Dataset):\n","    def __init__(self, image_dir, prompt_dir):\n","        self.image_dir = image_dir\n","        self.prompt_dir = prompt_dir\n","        self.image_filenames = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n","        self.prompts = [open(os.path.join(prompt_dir, f\"{os.path.splitext(f)[0]}.txt\")).read().strip() for f in self.image_filenames]\n","        self.transform = transforms.Compose([\n","            transforms.Resize((768, 768)),  # Resize images to 768x768\n","            transforms.ToTensor(),  # Convert to tensor\n","        ])\n","    \n","    def __len__(self):\n","        return len(self.image_filenames)\n","    \n","    def __getitem__(self, idx):\n","        image_path = os.path.join(self.image_dir, self.image_filenames[idx])\n","        image = Image.open(image_path).convert(\"RGB\")\n","        image = self.transform(image)  # Apply transformations\n","        prompt = self.prompts[idx]\n","        return image, prompt"]},{"cell_type":"markdown","metadata":{},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the dataset\n","dataset = CustomDataset(image_dir, prompt_dir)\n","dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n","\n","# Create an empty folder named 'result_data'\n","os.makedirs('result_data', exist_ok=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Fine Tuned"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 10\n","for epoch in range(num_epochs):\n","    for i, (image, prompt) in enumerate(dataloader):\n","        # Move image to device\n","        image = image.to(device)\n","\n","        # Generate images using the prompt\n","        generated_image = pipe(prompt[0], num_inference_steps=50, guidance_scale=7.5).images[0]  # Adjust parameters\n","        \n","        # Save the generated image\n","        generated_image.save(f\"result_data/generated_image_epoch{epoch + 1}_img{i + 1}.png\")"]},{"cell_type":"markdown","metadata":{},"source":["# Save Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T16:35:19.535332Z","iopub.status.busy":"2024-08-19T16:35:19.534383Z","iopub.status.idle":"2024-08-19T16:35:27.849612Z","shell.execute_reply":"2024-08-19T16:35:27.846909Z","shell.execute_reply.started":"2024-08-19T16:35:19.535296Z"},"trusted":true},"outputs":[],"source":["# Save the fine-tuned model\n","model_save_path = \"fine_tuned_model\"\n","os.makedirs(model_save_path, exist_ok=True)\n","pipe.save_pretrained(model_save_path)\n","tokenizer_save_path = os.path.join(model_save_path, \"tokenizer\")\n","os.makedirs(tokenizer_save_path, exist_ok=True)\n","pipe.tokenizer.save_pretrained(tokenizer_save_path)"]},{"cell_type":"markdown","metadata":{},"source":["# Make Directory"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T16:46:11.302625Z","iopub.status.busy":"2024-08-19T16:46:11.301968Z","iopub.status.idle":"2024-08-19T16:46:12.472478Z","shell.execute_reply":"2024-08-19T16:46:12.471306Z","shell.execute_reply.started":"2024-08-19T16:46:11.302591Z"},"trusted":true},"outputs":[],"source":["mkdir result"]},{"cell_type":"markdown","metadata":{},"source":["# Upload Model on Hugging"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T16:58:19.959181Z","iopub.status.busy":"2024-08-19T16:58:19.958232Z","iopub.status.idle":"2024-08-19T17:00:40.848199Z","shell.execute_reply":"2024-08-19T17:00:40.847144Z","shell.execute_reply.started":"2024-08-19T16:58:19.959143Z"},"trusted":true},"outputs":[],"source":["from huggingface_hub import HfApi, HfFolder, login\n","\n","# Authenticate with Hugging Face\n","token = ''  # Replace with your new token with write permission\n","login(token)\n","\n","# Initialize the Hugging Face API\n","api = HfApi()\n","\n","# Use the existing repository\n","model_repo = \"majid230/Realistic_Vision_V2.0\"\n","\n","# Path where your model is saved\n","model_save_path = \"fine_tuned_model\"  # Replace with your actual path\n","\n","# Upload the model to Hugging Face\n","api.upload_folder(\n","    folder_path=model_save_path,\n","    repo_id=model_repo,\n","    token=token,\n","    commit_message=\"Upload fine-tuned model\"\n",")\n","\n","print(f\"Model uploaded to {model_repo}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5565400,"sourceId":9204666,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
